{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-25T18:18:33.004306Z",
     "start_time": "2025-11-25T18:18:32.079013Z"
    }
   },
   "source": [
    "import helpers\n",
    "from multinomial_nb import MultinomialNaiveBayes\n",
    "\n",
    "DEPRESSION_PATH = \"data/depression_dataset_reddit_cleaned.csv\"\n",
    "TDT_SPLIT = \"80/10/10\"\n",
    "\n",
    "clean_text, is_depression = helpers.get_data(\n",
    "    datapath=DEPRESSION_PATH,\n",
    "    ngram=1,\n",
    "    tokenize=True,\n",
    "    by_character=False\n",
    ")\n",
    "\n",
    "depression_word = list(zip(clean_text, is_depression))\n",
    "\n",
    "print(\"Example row:\")\n",
    "print(depression_word[0])\n",
    "\n",
    "train, dev, test = helpers.split(depression_word, dist=TDT_SPLIT)\n",
    "\n",
    "print(f\"Train size: {len(train)}, Dev size: {len(dev)}, Test size: {len(test)}\")\n",
    "\n",
    "print(\"\\n=== Train Stats ===\")\n",
    "helpers.get_stats(train)\n",
    "\n",
    "print(\"\\n=== Dev Stats ===\")\n",
    "helpers.get_stats(dev)\n",
    "\n",
    "print(\"\\n=== Test Stats ===\")\n",
    "helpers.get_stats(test)\n",
    "\n",
    "nb_model = MultinomialNaiveBayes(alpha=1.0)\n",
    "nb_model.fit(train)\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "# Convert test set to tokens + labels\n",
    "y_true = [label for (_, label) in test_data]\n",
    "y_pred = [nb_model.predict_one(tokens) for (tokens, _) in test_data]\n",
    "\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "print(\"\\n=== Naive Bayes Final Metrics (Test Set) ===\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "\n",
    "# Row ready to copy into results CSV\n",
    "print(\"\\nCSV row:\")\n",
    "print(f\"naive_bayes,{precision},{recall},{f1},{accuracy}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example row:\n",
      "(['<s>', 'understand', 'people', 'reply', 'immediately', 'op', 'invitation', 'talk', 'privately', 'mean', 'help', 'type', 'response', 'usually', 'lead', 'either', 'disappointment', 'disaster', 'usually', 'work', 'quite', 'differently', 'say', 'pm', 'anytime', 'casual', 'social', 'context', 'huge', 'admiration', 'appreciation', 'goodwill', 'good', 'citizenship', 'many', 'support', 'others', 'flag', 'inappropriate', 'content', 'know', 'many', 'struggling', 'hard', 'work', 'behind', 'scene', 'information', 'resource', 'make', 'easier', 'give', 'get', 'quality', 'help', 'small', 'start', 'new', 'wiki', 'page', 'explains', 'detail', 'much', 'better', 'respond', 'public', 'comment', 'least', 'gotten', 'know', 'someone', 'maintained', 'r', 'wiki', 'private', 'contact', 'full', 'text', 'current', 'version', 'summary', 'anyone', 'acting', 'helper', 'invite', 'accepts', 'private', 'contact', 'e', 'pm', 'chat', 'kind', 'offsite', 'communication', 'early', 'conversion', 'showing', 'either', 'bad', 'intention', 'bad', 'judgement', 'either', 'way', 'unwise', 'trust', 'pm', 'anytime', 'seems', 'like', 'kind', 'generous', 'offer', 'might', 'perfectly', 'well', 'meaning', 'unless', 'solid', 'rapport', 'ha', 'established', 'wise', 'idea', 'point', 'consider', 'offer', 'accept', 'invitation', 'communicate', 'privately', 'posting', 'supportive', 'reply', 'publicly', 'help', 'people', 'op', 'response', 'good', 'quality', 'educate', 'inspire', 'helper', '9', '90', 'rule', 'en', 'wikipedia', 'org', 'wiki', 'rule', 'internet', 'culture', 'applies', 'much', 'doe', 'anywhere', 'else', 'internet', 'people', 'struggling', 'serious', 'mental', 'health', 'issue', 'often', 'justifiably', 'low', 'tolerance', 'disappointment', 'high', 'level', 'ever', 'changing', 'emotional', 'need', 'unless', 'helper', 'able', 'make', '00', 'commitment', 'every', 'way', 'long', 'necessary', 'offering', 'personal', 'inbox', 'resource', 'likely', 'harm', 'good', 'mental', 'health', 'crisis', 'line', 'responder', 'usually', 'give', 'name', 'caller', 'allowed', 'request', 'specific', 'responder', 'much', 'healthier', 'safer', 'caller', 'develop', 'relationship', 'agency', 'whole', 'analogously', 'much', 'safer', 'healthier', 'ops', 'develop', 'relationship', 'community', 'whole', 'trained', 'responder', 'generally', 'allowed', 'work', 'high', 'intensity', 'situation', 'alone', 'partly', 'availability', 'mostly', 'wider', 'perspective', 'preventing', 'compassion', 'fatigue', 'helper', 'get', 'head', 'someone', 'whose', 'mental', 'health', 'issue', 'including', 'suicidality', 'often', 'comorbid', 'escalate', 'pm', 'conversation', 'much', 'harder', 'others', 'including', 'r', 'r', 'suicidewatch', 'moderator', 'help', 'contrary', 'common', 'assumption', 'moderator', 'see', 'police', 'pm', 'observation', 'many', 'year', 'people', 'say', 'pm', 'consistently', 'one', 'least', 'understanding', 'mental', 'health', 'issue', 'mental', 'health', 'support', 'gap', 'knowledge', 'ability', 'communicate', 'effectively', 'community', 'input', 'mitigates', 'limitation', 'reason', 'someone', 'truly', 'help', 'would', 'want', 'hide', 'response', 'community', 'scrutiny', 'helper', 'concerned', 'privacy', 'keep', 'mind', 'self', 'disclosure', 'used', 'supportively', 'feeling', 'detail', 'problem', 'use', 'alt', 'throwaway', 'account', 'restriction', 'account', 'age', 'karma', 'know', 'internet', 'used', 'people', 'exploit', 'abuse', 'others', 'people', 'want', 'hide', 'deceptive', 'manipulative', 'response', 'everyone', 'except', 'victim', 'many', 'specifically', 'target', 'vulnerable', 'mental', 'health', 'issue', 'helper', 'invite', 'op', 'talk', 'privately', 'give', 'good', 'supportive', 'experience', 'primed', 'person', 'vulnerable', 'abuser', 'sort', 'cognitive', 'priming', 'tends', 'particularly', 'effective', 'someone', 'state', 'mental', 'health', 'crisis', 'people', 'rely', 'heuristic', 'critical', 'reasoning', 'ops', 'want', 'talk', 'privately', 'posting', 'wide', 'open', 'anonymous', 'forum', 'like', 'reddit', 'might', 'best', 'option', 'although', 'recommend', 'allow', 'ops', 'request', 'private', 'contact', 'asking', 'support', 'want', 'please', 'keep', 'expectation', 'realistic', 'careful', 'look', 'history', 'anyone', 'offer', 'pm', 'opening', '</s>'], 1)\n",
      "Completing 80/10/10 split\n",
      "Train size: 6184, Dev size: 773, Test size: 774\n",
      "\n",
      "=== Train Stats ===\n",
      "======================================================================\n",
      "Number of lines: 6184\n",
      "Number of tokens: 222933\n",
      "Number of unique tokens: 16656\n",
      "Number of YES depression entries: 3067 (49.60%)\n",
      "Number of NOT depression entries: 3117 (50.40%)\n",
      "======================================================================\n",
      "\n",
      "=== Dev Stats ===\n",
      "======================================================================\n",
      "Number of lines: 773\n",
      "Number of tokens: 27496\n",
      "Number of unique tokens: 5050\n",
      "Number of YES depression entries: 392 (50.71%)\n",
      "Number of NOT depression entries: 381 (49.29%)\n",
      "======================================================================\n",
      "\n",
      "=== Test Stats ===\n",
      "======================================================================\n",
      "Number of lines: 774\n",
      "Number of tokens: 27641\n",
      "Number of unique tokens: 4976\n",
      "Number of YES depression entries: 372 (48.06%)\n",
      "Number of NOT depression entries: 402 (51.94%)\n",
      "======================================================================\n",
      "\n",
      "=== Naive Bayes Final Metrics (Test Set) ===\n",
      "Precision: 0.9129\n",
      "Recall:    0.8737\n",
      "F1 Score:  0.8929\n",
      "Accuracy:  0.8992\n",
      "\n",
      "CSV row:\n",
      "naive_bayes,0.9129213483146067,0.8736559139784946,0.8928571428571429,0.8992248062015504\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T18:21:43.022689Z",
     "start_time": "2025-11-25T18:21:43.018823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import csv\n",
    "\n",
    "row = [\n",
    "    \"naive_bayes\",\n",
    "    0.9129213483146067,\n",
    "    0.8736559139784946,\n",
    "    0.8928571428571429,\n",
    "    0.8992248062015504\n",
    "]\n",
    "\n",
    "csv_path = \"results/results.csv\"\n",
    "\n",
    "with open(csv_path, \"a\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(row)\n",
    "\n",
    "print(\"Row appended to results.csv\")"
   ],
   "id": "d23ff779e358f215",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row appended to results.csv\n"
     ]
    }
   ],
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
